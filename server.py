import os, subprocess, hashlib, urllib.parse, unicodedata, threading, time, json, re, sys, traceback, shutil, requests, random, mimetypes
from flask import Flask, jsonify, send_from_directory, request, Response, redirect, send_file
from flask_cors import CORS
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime

app = Flask(__name__)
CORS(app)

# MIME íƒ€ì… ì¶”ê°€ ë“±ë¡
if not mimetypes.types_map.get('.mkv'): mimetypes.add_type('video/x-matroska', '.mkv')
if not mimetypes.types_map.get('.ts'): mimetypes.add_type('video/mp2t', '.ts')
if not mimetypes.types_map.get('.tp'): mimetypes.add_type('video/mp2t', '.tp')

# --- [1. ì„¤ì • ë° ê²½ë¡œ] ---
MY_IP = "192.168.0.2"
DATA_DIR = "/volume2/video/thumbnails"
CACHE_FILE = "/volume2/video/video_cache.json"
TMDB_CACHE_DIR = "/volume2/video/tmdb_cache"
HLS_ROOT = "/dev/shm/videoplayer_hls"
CACHE_VERSION = "9.7" # ê·œì¹™: ë²„ì „ ìœ ì§€ë¡œ ê¸°ì¡´ ë°ì´í„° ë³´ì¡´

# TMDB API KEY
TMDB_API_KEY = "eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI3OGNiYWQ0ZjQ3NzcwYjYyYmZkMTcwNTA2NDIwZDQyYyIsIm5iZiI6MTY1MzY3NTU4MC45MTUsInN1YiI6IjYyOTExNjNjMTI0MjVjMDA1MjI0ZGQzNCIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.3YU0WuIx_WDo6nTRKehRtn4N5I4uCgjI1tlpkqfsUhk".strip()
TMDB_BASE_URL = "https://api.themoviedb.org/3"

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(TMDB_CACHE_DIR, exist_ok=True)
if os.path.exists(HLS_ROOT): shutil.rmtree(HLS_ROOT, ignore_errors=True)
os.makedirs(HLS_ROOT, exist_ok=True)

PARENT_VIDEO_DIR = "/volume2/video/GDS3/GDRIVE/VIDEO"
FOREIGN_TV_DIR = os.path.join(PARENT_VIDEO_DIR, "ì™¸êµ­TV")
KOREAN_TV_DIR = os.path.join(PARENT_VIDEO_DIR, "êµ­ë‚´TV")
MOVIES_ROOT_DIR = os.path.join(PARENT_VIDEO_DIR, "ì˜í™”")
ANI_DIR = os.path.join(PARENT_VIDEO_DIR, "ì¼ë³¸ ì• ë‹ˆë©”ì´ì…˜")
AIR_DIR = os.path.join(PARENT_VIDEO_DIR, "ë°©ì†¡ì¤‘")

PATH_MAP = {
    "ì™¸êµ­TV": (FOREIGN_TV_DIR, "ftv"),
    "êµ­ë‚´TV": (KOREAN_TV_DIR, "ktv"),
    "ì˜í™”": (MOVIES_ROOT_DIR, "movie"),
    "ì• ë‹ˆë©”ì´ì…˜": (ANI_DIR, "anim_all"),
    "ì¼ë³¸ ì• ë‹ˆë©”ì´ì…˜": (ANI_DIR, "anim_all"),
    "ë°©ì†¡ì¤‘": (AIR_DIR, "air")
}

EXCLUDE_FOLDERS = ["ì„±ì¸", "19ê¸ˆ", "Adult", "@eaDir", "#recycle"]
VIDEO_EXTS = ('.mp4', '.mkv', '.avi', '.wmv', '.flv', '.ts', '.tp', '.m4v', '.m2ts', '.mov')
FFMPEG_PATH = "ffmpeg"
for p in ["/usr/local/bin/ffmpeg", "/var/packages/ffmpeg/target/bin/ffmpeg", "/usr/bin/ffmpeg"]:
    if os.path.exists(p): FFMPEG_PATH = p; break

GLOBAL_CACHE = {
    "air": [], "movies": [], "foreigntv": [], "koreantv": [],
    "animations_all": [], "search_index": [], "home_recommend": [], "version": CACHE_VERSION
}

def log(msg):
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {msg}", flush=True)

def nfc(text): return unicodedata.normalize('NFC', text) if text else ""
def nfd(text): return unicodedata.normalize('NFD', text) if text else ""

# --- [ì •ê·œì‹ ë° ìœ í‹¸ë¦¬í‹°] ---
REGEX_EXT = re.compile(r'\.[a-zA-Z0-9]{2,4}$')
REGEX_YEAR = re.compile(r'\((19|20)\d{2}\)|(?<!\d)(19|20)\d{2}(?!\d)')
REGEX_EP_MARKER = re.compile(r'(?i)(?:^|[.\s_]|(?<=[ê°€-í£]))(?:S\d+E\d+|S\d+|E\d+|\d+\s*(?:í™”|íšŒ|ê¸°)|Season\s*\d+|Part\s*\d+).*')
REGEX_FORBIDDEN_TITLE = re.compile(r'(?i)^\s*(Season\s*\d+|Part\s*\d+|EP\s*\d+|\d+í™”|\d+íšŒ|\d+ê¸°|ì‹œì¦Œ\s*\d+|S\d+|E\d+)\s*$', re.I)

def clean_title_complex(title):
    if not title: return "", None
    title = nfc(title)
    cleaned = REGEX_EXT.sub('', title)
    year_match = REGEX_YEAR.search(cleaned)
    year = year_match.group().replace('(', '').replace(')', '') if year_match else None
    cleaned = REGEX_YEAR.sub(' ', cleaned)
    cleaned = REGEX_EP_MARKER.sub(' ', cleaned)
    cleaned = re.sub(r'\[.*?\]|\(.*?\)', ' ', cleaned)
    cleaned = re.sub(r'[._\-!?ã€ã€‘ã€ã€ã€Œã€"\'#@*â€»:]', ' ', cleaned)
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    return cleaned, year

def get_real_path(path):
    if not path: return path
    if os.path.exists(path): return path
    p_nfc, p_nfd = nfc(path), nfd(path)
    if os.path.exists(p_nfc): return p_nfc
    if os.path.exists(p_nfd): return p_nfd
    return path

def resolve_nas_path(app_path):
    if not app_path: return None, None
    app_path = nfc(urllib.parse.unquote(app_path))
    parts = app_path.split('/')
    prefix = parts[0]
    if prefix in PATH_MAP:
        base_dir, type_code = PATH_MAP[prefix]
        rel_path = "/".join(parts[1:])
        resolved = get_real_path(os.path.join(base_dir, rel_path))
        return resolved, type_code
    return None, None

def get_tmdb_info_server(title, ignore_cache=False, log_path=None, search_override=None):
    if not title: return {"failed": True}
    title_pure = nfc(title).split('/')[-1]
    cp = os.path.join(TMDB_CACHE_DIR, f"{hashlib.md5(title_pure.encode()).hexdigest()}.json")
    if not ignore_cache and os.path.exists(cp):
        try:
            with open(cp, 'r', encoding='utf-8') as f: return json.load(f)
        except: pass

    # ê²€ìƒ‰ í…ìŠ¤íŠ¸ ê²°ì •: override ìš°ì„ 
    query_text = search_override if search_override else title_pure
    ct, year = clean_title_complex(query_text)

    if not search_override and (REGEX_FORBIDDEN_TITLE.match(ct) or ct.lower() in ["season", "series", "video", "episode"]):
        info = {"failed": True, "forbidden": True}
        with open(cp, 'w', encoding='utf-8') as f: json.dump(info, f, ensure_ascii=False)
        return info

    path_info = f" (ê²½ë¡œ: {log_path})" if log_path else ""
    log(f"  [TMDB-SEARCH] '{query_text}' -> '{ct}' ({year}){path_info}")

    params = {"query": ct, "language": "ko-KR", "include_adult": "false", "region": "KR"}
    if year: params["year"] = year
    headers = {"Authorization": f"Bearer {TMDB_API_KEY}"} if TMDB_API_KEY.startswith("eyJ") else {}
    if not headers: params["api_key"] = TMDB_API_KEY

    try:
        resp = requests.get(f"{TMDB_BASE_URL}/search/multi", params=params, headers=headers, timeout=5).json()
        results = [r for r in resp.get('results', []) if r.get('media_type') in ['movie', 'tv']]
        if results:
            best = results[0]
            m_type, t_id = best.get('media_type'), best.get('id')
            d_resp = requests.get(f"{TMDB_BASE_URL}/{m_type}/{t_id}?language=ko-KR&append_to_response=content_ratings", params=params, headers=headers, timeout=5).json()
            year_val = (d_resp.get('release_date') or d_resp.get('first_air_date') or "").split('-')[0]
            rating = None
            if 'content_ratings' in d_resp:
                results_list = d_resp['content_ratings'].get('results', [])
                kr = next((r['rating'] for r in results_list if r.get('iso_3166_1') == 'KR'), None)
                if kr: rating = f"{kr}+" if kr.isdigit() else kr
            info = {"genreIds": [g['id'] for g in d_resp.get('genres', [])], "posterPath": d_resp.get('poster_path'), "year": year_val, "overview": d_resp.get('overview'), "rating": rating, "seasonCount": d_resp.get('number_of_seasons'), "failed": False}
            with open(cp, 'w', encoding='utf-8') as f: json.dump(info, f, ensure_ascii=False)
            return info
    except: pass
    with open(cp, 'w', encoding='utf-8') as f: json.dump({"failed": True}, f, ensure_ascii=False)
    return {"failed": True}

def attach_tmdb_info(cat):
    name = cat.get('name')
    if name:
        info = get_tmdb_info_server(name, log_path=cat.get('path'))
        cat.update(info)
    return cat

def fetch_metadata_async(force_all=False):
    log("ğŸš€ [METADATA] ë°±ê·¸ë¼ìš´ë“œ ë§¤ì¹­ ì‹œì‘")
    tasks = []
    # ë°ì´í„° ìˆ˜ì§‘ (ì–´ë–¤ ì¹´í…Œê³ ë¦¬ì˜ ì–´ë–¤ ê²½ë¡œì¸ì§€ ì •ë³´ë¥¼ ìœ ì§€)
    for k in ["animations_all", "foreigntv", "koreantv", "movies", "air"]:
        for cat in GLOBAL_CACHE.get(k, []):
            if force_all or (not cat.get('posterPath') and not cat.get('failed')):
                tasks.append((cat, k))

    total = len(tasks)
    log(f"  ğŸ“‹ ì´ {total}ê°œì˜ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ í•„ìš”")
    count = 0
    for cat, cat_key in tasks:
        # ê²€ìƒ‰ ì‹œ ê²½ë¡œ ì •ë³´ë¥¼ ë„˜ê²¨ì„œ ë¡œê·¸ì— ì°íˆê²Œ í•¨
        info = get_tmdb_info_server(cat['name'], ignore_cache=force_all, log_path=f"{cat_key}/{cat.get('path')}")
        cat.update(info)
        count += 1
        if count % 10 == 0:
            log(f"  â³ ë§¤ì¹­ ì¤‘... ({count}/{total})")
            save_cache()
        time.sleep(0.1)

    build_home_recommend(); save_cache()
    log("ğŸ [METADATA] ëª¨ë“  ì‘ì—… ì™„ë£Œ")

def scan_recursive(bp, prefix, rb=None):
    cats = []
    exts = VIDEO_EXTS
    p, rel_base = get_real_path(bp), get_real_path(rb) if rb else get_real_path(bp)

    log(f"    [SCAN] ê²½ë¡œ ì§„ì…: {p}")
    if not os.path.exists(p):
        log(f"    âš ï¸ ê²½ë¡œ ì—†ìŒ: {p}")
        return cats

    all_f = []
    file_count = 0

    def fast_walk_iterative(target_path):
        nonlocal file_count
        stack = [target_path]
        while stack:
            current = stack.pop()
            try:
                with os.scandir(current) as it:
                    for entry in it:
                        if entry.is_dir():
                            if not any(ex in entry.name for ex in EXCLUDE_FOLDERS) and not entry.name.startswith('.'):
                                stack.append(entry.path)
                        elif entry.is_file():
                            if entry.name.lower().endswith(exts):
                                all_f.append(entry.path)
                                file_count += 1
                                if file_count % 1000 == 0:
                                    log(f"    >>> {file_count}ê°œ íŒŒì¼ ë°œê²¬ ì¤‘... ({entry.name[:20]})")
            except: pass

    log(f"    ğŸ” ê³ ì† íƒìƒ‰ ì‹œì‘ (os.scandir ë°˜ë³µë¬¸)...")
    fast_walk_iterative(p)

    log(f"    ğŸ“¦ íƒìƒ‰ ì™„ë£Œ! ì´ {file_count}ê°œ íŒŒì¼ ë¶„ì„ ë° ê·¸ë£¹í™” ì‹œì‘...")
    all_f.sort()
    curr, movies = "", []
    for fp in all_f:
        dp = os.path.dirname(fp)
        if dp != curr:
            if movies:
                rel_path = nfc(os.path.relpath(curr, rel_base))

                # [í•µì‹¬ ìˆ˜ì •] ê°€ì§œ ì œëª© êµì • ë¡œì§ ì‚½ì… (ê·œì¹™: ê¸°ì¡´ ë¡œì§ ë³´ì¡´ ë° ì£¼ì„ ìœ ì§€)
                name = nfc(os.path.basename(curr))
                if REGEX_FORBIDDEN_TITLE.match(name) or name.lower() in ["season", "series", "episode"]:
                    parent_dir = os.path.dirname(curr)
                    parent_name = nfc(os.path.basename(parent_dir))
                    if parent_name and not REGEX_FORBIDDEN_TITLE.match(parent_name):
                        name = parent_name # ë¶€ëª¨ í´ë”ëª…ì„ ì§„ì§œ ì œëª©ìœ¼ë¡œ ì±„íƒ

                cats.append({"name": name, "movies": movies, "path": rel_path})
            curr, movies = dp, []
        movies.append(get_movie_info(fp, rel_base, prefix))
    if movies:
        rel_path = nfc(os.path.relpath(curr, rel_base))
        name = nfc(os.path.basename(curr))
        if REGEX_FORBIDDEN_TITLE.match(name):
            parent_name = nfc(os.path.basename(os.path.dirname(curr)))
            if parent_name: name = parent_name
        cats.append({"name": name, "movies": movies, "path": rel_path})

    log(f"    âœ… ê·¸ë£¹í™” ì™„ë£Œ: {len(cats)}ê°œ ì¹´í…Œê³ ë¦¬ ìƒì„±")
    return cats

def get_movie_info(fp, base, prefix):
    rel = nfc(os.path.relpath(fp, base))
    tid = hashlib.md5(f"{prefix}_{rel}".encode()).hexdigest() + ".jpg"
    return {"id": tid, "title": os.path.basename(fp), "videoUrl": f"/video_serve?type={prefix}&path={urllib.parse.quote(rel)}", "thumbnailUrl": f"/thumb_serve?type={prefix}&id={tid}&path={urllib.parse.quote(rel)}"}

def build_home_recommend():
    log("ğŸ  [HOME] ê³ ì† ì¶”ì²œ ëª©ë¡ ë¹Œë“œ ì¤‘...")
    def prep(items, prefix):
        res = []
        for it in items:
            c = it.copy(); c['movies'] = []
            if c.get('path') and not c['path'].startswith(prefix): c['path'] = f"{prefix}/{c['path']}"
            res.append(c)
        return res
    m, a, k, f = prep(GLOBAL_CACHE.get("movies", []), "ì˜í™”"), prep(GLOBAL_CACHE.get("animations_all", []), "ì• ë‹ˆë©”ì´ì…˜"), prep(GLOBAL_CACHE.get("koreantv", []), "êµ­ë‚´TV"), prep(GLOBAL_CACHE.get("foreigntv", []), "ì™¸êµ­TV")
    all_p = list(m + a + k + f); random.shuffle(all_p)
    GLOBAL_CACHE["home_recommend"] = [
        {"title": "ì§€ê¸ˆ ê°€ì¥ í•«í•œ ì¸ê¸°ì‘", "items": all_p[:20]},
        {"title": "ë°©ê¸ˆ ì˜¬ë¼ì˜¨ ìµœì‹  ì˜í™”", "items": m[:20]},
        {"title": "ì§€ê¸ˆ ì¸ê¸° ìˆëŠ” ì‹œë¦¬ì¦ˆ", "items": (k + f)[:20]},
        {"title": "ì¶”ì²œ ì• ë‹ˆë©”ì´ì…˜", "items": a[:20]}
    ]

def perform_full_scan(reason="í•„ìš”"):
    log(f"\nğŸ”„ ì‚¬ìœ : {reason} -> ë°±ê·¸ë¼ìš´ë“œ íƒìƒ‰ ì‹œì‘ (ìš°ì„ ìˆœìœ„ ìˆœ)")
    # ìš”ì²­í•˜ì‹  ìˆœì„œ: ì• ë‹ˆë©”ì´ì…˜ -> ì™¸êµ­TV -> êµ­ë‚´TV -> ì˜í™” -> ë°©ì†¡ì¤‘
    t = [
        ("ì• ë‹ˆë©”ì´ì…˜", ANI_DIR, "anim_all", "animations_all"),
        ("ì™¸êµ­TV", FOREIGN_TV_DIR, "ftv", "foreigntv"),
        ("êµ­ë‚´TV", KOREAN_TV_DIR, "ktv", "koreantv"),
        ("ì˜í™”", MOVIES_ROOT_DIR, "movie", "movies"),
        ("ë°©ì†¡ì¤‘", AIR_DIR, "air", "air")
    ]
    for label, path, prefix, cache_key in t:
        if GLOBAL_CACHE.get(cache_key) and len(GLOBAL_CACHE[cache_key]) > 0:
             log(f"  â­ï¸ [{label}] ì´ë¯¸ ë¡œë“œëœ ë°ì´í„°ê°€ ìˆìŒ. ê±´ë„ˆëœë‹ˆë‹¤.")
             continue

        log(f"  ğŸ“‚ [{label}] íƒìƒ‰ ì‹œì‘")
        try:
            results = scan_recursive(path, prefix)
            GLOBAL_CACHE[cache_key] = results
            log(f"  âœ… [{label}] ì™„ë£Œ! ì¦‰ì‹œ ë°˜ì˜ ì¤‘")
            build_home_recommend(); save_cache() # ì¹´í…Œê³ ë¦¬ ëë‚  ë•Œë§ˆë‹¤ ì¦‰ì‹œ ë…¸ì¶œ
        except Exception as e:
            log(f"  âŒ [{label}] ì˜¤ë¥˜: {e}")

    log("ğŸ’¾ ëª¨ë“  íƒìƒ‰ ì™„ë£Œ. ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    threading.Thread(target=fetch_metadata_async, daemon=True).start()

def load_cache():
    if not os.path.exists(CACHE_FILE):
        log(f"âš ï¸ [WARNING] ìºì‹œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CACHE_FILE}")
        return False

    try:
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            content = f.read()
            if not content.strip(): return False

            # [ê¹¨ì§„ JSON ì‹¬íì†Œìƒ ë¡œì§]
            try:
                d = json.loads(content)
            except json.JSONDecodeError as je:
                log(f"âŒ [ERROR] ìºì‹œ íŒŒì¼ì´ ë¬¸ë²•ì ìœ¼ë¡œ ê¹¨ì ¸ìˆìŠµë‹ˆë‹¤: {je}")
                log("ğŸ› ï¸ [HEAL] ìºì‹œ íŒŒì¼ ìë™ ë³µêµ¬(Heal)ë¥¼ ì‹œë„í•©ë‹ˆë‹¤...")
                healed = False
                # ëŠê¸´ ì§€ì ì— ë”°ë¼ ë‹«ëŠ” íƒœê·¸ë“¤ì„ ì¡°í•©í•˜ì—¬ ì‹œë„
                for suffix in ["}", "}]", "]}", "}}]"]:
                    try:
                        d = json.loads(content + suffix)
                        log(f"âœ… [HEAL] '{suffix}'ë¥¼ ì¶”ê°€í•˜ì—¬ ë°ì´í„° ë³µêµ¬ì— ì„±ê³µí–ˆìŠµë‹ˆë‹¤!")
                        healed = True
                        break
                    except: continue

                if not healed:
                    shutil.copy(CACHE_FILE, CACHE_FILE + ".bak")
                    log(f"ğŸ’¾ ë³µêµ¬ ì‹¤íŒ¨. ê¹¨ì§„ ìºì‹œë¥¼ ë°±ì—…í–ˆìŠµë‹ˆë‹¤: {CACHE_FILE}.bak")
                    return False

            file_version = d.get("version", "ì•Œ ìˆ˜ ì—†ìŒ")
            log(f"ğŸ” [CACHE] ìºì‹œ íŒŒì¼ ë¡œë“œ ì‹œë„ (ë²„ì „: {file_version})")

            # [ê°•ì œ ë¡œë“œ ë¡œì§] ê·œì¹™: ë²„ì „ì´ ë‹¬ë¼ë„ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ìŠ¤ìº” ë°©ì§€
            GLOBAL_CACHE.update(d)
            GLOBAL_CACHE["version"] = CACHE_VERSION
            log(f"ğŸ“‚ [CACHE] ê¸°ì¡´ ë°ì´í„° ê°•ì œ ë¡œë“œ ì„±ê³µ (v{file_version} -> v{CACHE_VERSION})")

            # [ì¦‰ì‹œ êµì •] ë¡œë“œëœ ìºì‹œì˜ ì œëª©ì„ ì¦‰ì‹œ êµì •í•˜ì—¬ ì•±ì— ë°˜ì˜
            log("ğŸ› ï¸ [MIGRATION] ê¸°ì¡´ ìºì‹œ ì œëª© êµì • ì‘ì—… ì‹œì‘...")
            for k in ["animations_all", "foreigntv", "koreantv", "movies", "air"]:
                items_list = GLOBAL_CACHE.get(k, [])
                if not items_list: continue

                for item in items_list:
                    current_name = item.get('name', '')
                    if REGEX_FORBIDDEN_TITLE.match(current_name) or current_name.lower() in ["season", "series"]:
                        path_val = item.get('path', '')
                        path_parts = path_val.split('/')
                        if len(path_parts) >= 2:
                            item['name'] = nfc(path_parts[-2])
            log("âœ… [MIGRATION] ì œëª© êµì • ì™„ë£Œ!")
            return True
    except Exception as e:
        log(f"âŒ [ERROR] ìºì‹œ ë¡œë“œ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
    return False

def save_cache():
    try:
        # ì•ˆì „í•œ ì €ì¥ì„ ìœ„í•´ ì„ì‹œ íŒŒì¼ì— ì“°ê³  ì´ë¦„ì„ ë°”ê¾¸ëŠ” ë°©ì‹ ì±„íƒ (íŒŒì¼ ê¹¨ì§ ë°©ì§€)
        temp_file = CACHE_FILE + ".tmp"
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(GLOBAL_CACHE, f, ensure_ascii=False)
        os.replace(temp_file, CACHE_FILE)
    except: pass

def init_server():
    log(f"ğŸ“º NAS Server v{CACHE_VERSION} ì¦‰ì‹œ ì‹œì‘")
    has_cache = load_cache()
    if has_cache: build_home_recommend()

    # ì„œë²„ ì‘ë‹µì„ ìœ„í•´ íƒìƒ‰ì€ ë¬´ì¡°ê±´ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ì‹¤í–‰
    threading.Thread(target=perform_full_scan, args=("ì‹œìŠ¤í…œ ì‹œì‘",), daemon=True).start()

init_server()

# --- [API ì—”ë“œí¬ì¸íŠ¸] ---
@app.route('/home')
def get_home(): return jsonify(GLOBAL_CACHE.get("home_recommend", []))
@app.route('/scan')
def manual_scan(): threading.Thread(target=perform_full_scan, args=("ì‚¬ìš©ì ìš”ì²­",)).start(); return "ìŠ¤ìº” ì‹œì‘"
@app.route('/refresh_metadata')
def refresh_metadata(): threading.Thread(target=fetch_metadata_async, kwargs={"force_all": True}).start(); return "ë©”íƒ€ë°ì´í„° ì¬ë§¤ì¹­ ì‹œì‘"

@app.route('/debug_match')
def debug_match():
    q = request.args.get('q', '')
    s = request.args.get('search', '')
    if not q: return "Usage: /debug_match?q=ëŒ€ìƒí´ë”ëª…&search=ê²€ìƒ‰í‚¤ì›Œë“œ"
    info = get_tmdb_info_server(q, ignore_cache=True, search_override=s)
    target_q = nfc(q)
    updated_count = 0
    for k in ["animations_all", "foreigntv", "koreantv", "movies", "air"]:
        for cat in GLOBAL_CACHE.get(k, []):
            if nfc(cat['name']) == target_q:
                cat.update(info)
                updated_count += 1
    if updated_count > 0:
        save_cache()
        build_home_recommend()
        return jsonify({"status": "success", "folder": q, "query_used": s if s else q, "data": info})
    else:
        return jsonify({"status": "partial_success", "message": "ìºì‹œëŠ” ìƒì„±ë˜ì—ˆìœ¼ë‚˜ í˜„ì¬ ëª©ë¡ì—ì„œ í´ë”ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "data": info})

def process_data(data, lite=False, is_search=False):
    # í˜ì´ì§• ì§€ì›
    limit = request.args.get('limit', type=int)
    offset = request.args.get('offset', type=int, default=0)

    result = data
    if request.args.get('random') == 'true':
        result = list(data)
        rng = random.Random(datetime.now().strftime("%Y%m%d"))
        rng.shuffle(result)

    if offset: result = result[offset:]
    if limit: result = result[:limit]

    if lite:
        return [{"name": c.get('name',''), "path": c.get('path',''), "movies": c.get('movies', []) if is_search else [], "genreIds": c.get('genreIds', []), "posterPath": c.get('posterPath'), "year": c.get('year'), "overview": c.get('overview'), "rating": c.get('rating'), "seasonCount": c.get('seasonCount'), "failed": c.get('failed', False)} for c in result]
    return result

def filter_by_path(pool, keyword):
    target = nfc(keyword).replace(" ", "").lower()
    return [c for c in pool if target in nfc(c.get('path', '')).replace(" ", "").lower()]

@app.route('/air')
@app.route('/air_animations')
@app.route('/air_dramas')
def get_air():
    pool = GLOBAL_CACHE.get("air", [])
    if "animations" in request.path: pool = filter_by_path(pool, "ì• ë‹ˆë©”ì´ì…˜")
    elif "dramas" in request.path: pool = filter_by_path(pool, "ë“œë¼ë§ˆ")
    return jsonify(process_data(pool, request.args.get('lite') == 'true'))

@app.route('/animations_all')
@app.route('/anim_raftel')
@app.route('/anim_series')
def get_animations_all(): return jsonify(process_data(GLOBAL_CACHE.get("animations_all", []), request.args.get('lite') == 'true'))

@app.route('/foreigntv')
@app.route('/ftv_us')
@app.route('/ftv_cn')
@app.route('/ftv_jp')
@app.route('/ftv_docu')
@app.route('/ftv_etc')
def get_foreigntv(): return jsonify(process_data(GLOBAL_CACHE.get("foreigntv", []), request.args.get('lite') == 'true'))

@app.route('/koreantv')
@app.route('/ktv_drama')
@app.route('/ktv_sitcom')
@app.route('/ktv_variety')
@app.route('/ktv_edu')
@app.route('/ktv_docu')
def get_koreantv(): return jsonify(process_data(GLOBAL_CACHE.get("koreantv", []), request.args.get('lite') == 'true'))

@app.route('/movies')
@app.route('/movies_latest')
@app.route('/movies_uhd')
@app.route('/movies_title')
def get_movies(): return jsonify(process_data(GLOBAL_CACHE.get("movies", []), request.args.get('lite') == 'true'))

@app.route('/search')
def search_videos():
    q = request.args.get('q', '').lower()

    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ prefix ë§¤í•‘
    mapping = [
        ("ì˜í™”", GLOBAL_CACHE.get('movies', [])),
        ("ì• ë‹ˆë©”ì´ì…˜", GLOBAL_CACHE.get('animations_all', [])),
        ("ì™¸êµ­TV", GLOBAL_CACHE.get('foreigntv', [])),
        ("êµ­ë‚´TV", GLOBAL_CACHE.get('koreantv', [])),
        ("ë°©ì†¡ì¤‘", GLOBAL_CACHE.get('air', []))
    ]

    res = []
    for prefix, pool in mapping:
        for cat in pool:
            if q in cat['name'].lower():
                nc = cat.copy()
                if nc.get('path') and not nc['path'].startswith(prefix):
                    nc['path'] = f"{prefix}/{nc['path']}"
                res.append(nc)
            else:
                fm = [m for m in cat.get('movies', []) if q in m['title'].lower()]
                if fm:
                    nc = cat.copy()
                    nc['movies'] = fm
                    if nc.get('path') and not nc['path'].startswith(prefix):
                        nc['path'] = f"{prefix}/{nc['path']}"
                    res.append(nc)
    return jsonify(process_data(res, lite=request.args.get('lite') == 'true', is_search=True))

@app.route('/list')
def get_list():
    path = request.args.get('path')
    if not path: return jsonify([])
    real_path, type_code = resolve_nas_path(path)
    if not real_path or not os.path.exists(real_path): return jsonify([])
    base_dir = PATH_MAP.get(path.split('/')[0], (None, None))[0]
    res, movies = [], []
    for entry in sorted(os.listdir(real_path)):
        fe = os.path.join(real_path, entry)
        if os.path.isdir(fe):
            if any(ex in entry for ex in EXCLUDE_FOLDERS): continue

            # [í•µì‹¬ ìˆ˜ì •] ìƒì„¸í˜ì´ì§€ ì¬ìƒ ë²„íŠ¼ í™œì„±í™”ë¥¼ ìœ„í•œ í•˜ìœ„ í´ë” ìŠ¤ìº”
            sub_movies = []
            try:
                for f in sorted(os.listdir(fe)):
                    if f.lower().endswith(VIDEO_EXTS):
                        sub_movies.append(get_movie_info(os.path.join(fe, f), base_dir, type_code))
            except: pass

            name = nfc(entry)
            # ê°€ì§œ ì œëª© êµì •: Season 1 ë“± ê¸ˆì§€ëœ ì œëª©ì´ë©´ ë¶€ëª¨ ì´ë¦„ì„ ì œëª©ìœ¼ë¡œ ì¡°í•©
            if REGEX_FORBIDDEN_TITLE.match(name):
                p_name = nfc(os.path.basename(real_path))
                if p_name: name = f"{p_name} ({name})"

            res.append(attach_tmdb_info({"name": name, "path": nfc(os.path.relpath(fe, base_dir)), "movies": sub_movies}))
        elif entry.lower().endswith(VIDEO_EXTS):
            movies.append(get_movie_info(fe, base_dir, type_code))

    if movies:
        res.append({"name": nfc(os.path.basename(real_path)), "path": nfc(os.path.relpath(real_path, base_dir)), "movies": movies})

    return jsonify(res)

@app.route('/video_serve')
def video_serve():
    path, prefix = request.args.get('path'), request.args.get('type')
    base = {"ftv": FOREIGN_TV_DIR, "ktv": KOREAN_TV_DIR, "air": AIR_DIR, "anim_all": ANI_DIR, "movie": MOVIES_ROOT_DIR}.get(prefix)
    fp = get_real_path(os.path.join(base, nfc(urllib.parse.unquote(path))))
    return send_file(fp, conditional=True)

@app.route('/thumb_serve')
def thumb_serve():
    path, prefix, tid = request.args.get('path'), request.args.get('type'), request.args.get('id')
    try:
        t_raw = float(request.args.get('t', '300'))
        t = int(round(t_raw / 10.0) * 10)
    except: t = 300
    base = {"ftv": FOREIGN_TV_DIR, "ktv": KOREAN_TV_DIR, "air": AIR_DIR, "anim_all": ANI_DIR, "movie": MOVIES_ROOT_DIR}.get(prefix)
    vp = get_real_path(os.path.join(base, nfc(urllib.parse.unquote(path))))
    if os.path.isdir(vp):
        fs = sorted([f for f in os.listdir(vp) if f.lower().endswith(VIDEO_EXTS)])
        if fs: vp = os.path.join(vp, fs[0])
    tp = os.path.join(DATA_DIR, f"seek_{t}_{tid}")
    if not os.path.exists(tp):
        try: subprocess.run([FFMPEG_PATH, "-y", "-ss", str(t), "-i", vp, "-vframes", "1", "-q:v", "5", "-vf", "scale=320:-1", tp], timeout=10)
        except: pass
    return send_file(tp, mimetype='image/jpeg') if os.path.exists(tp) else ("Not Found", 404)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, threaded=True)
